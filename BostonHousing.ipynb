{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.0.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow\n",
    "tensorflow.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "random.seed(0)\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/boston_housing.npz\n",
      "57344/57026 [==============================] - 0s 2us/step\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.datasets import boston_housing\n",
    "(features, actual_prices) = boston_housing.load_data(test_split = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(506, 13)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0,)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actual_prices[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[1.23247e+00, 0.00000e+00, 8.14000e+00, ..., 2.10000e+01,\n",
       "         3.96900e+02, 1.87200e+01],\n",
       "        [2.17700e-02, 8.25000e+01, 2.03000e+00, ..., 1.47000e+01,\n",
       "         3.95380e+02, 3.11000e+00],\n",
       "        [4.89822e+00, 0.00000e+00, 1.81000e+01, ..., 2.02000e+01,\n",
       "         3.75520e+02, 3.26000e+00],\n",
       "        ...,\n",
       "        [1.83377e+00, 0.00000e+00, 1.95800e+01, ..., 1.47000e+01,\n",
       "         3.89610e+02, 1.92000e+00],\n",
       "        [3.58090e-01, 0.00000e+00, 6.20000e+00, ..., 1.74000e+01,\n",
       "         3.91700e+02, 9.71000e+00],\n",
       "        [2.92400e+00, 0.00000e+00, 1.95800e+01, ..., 1.47000e+01,\n",
       "         2.40160e+02, 9.81000e+00]]),\n",
       " array([15.2, 42.3, 50. , 21.1, 17.7, 18.5, 11.3, 15.6, 15.6, 14.4, 12.1,\n",
       "        17.9, 23.1, 19.9, 15.7,  8.8, 50. , 22.5, 24.1, 27.5, 10.9, 30.8,\n",
       "        32.9, 24. , 18.5, 13.3, 22.9, 34.7, 16.6, 17.5, 22.3, 16.1, 14.9,\n",
       "        23.1, 34.9, 25. , 13.9, 13.1, 20.4, 20. , 15.2, 24.7, 22.2, 16.7,\n",
       "        12.7, 15.6, 18.4, 21. , 30.1, 15.1, 18.7,  9.6, 31.5, 24.8, 19.1,\n",
       "        22. , 14.5, 11. , 32. , 29.4, 20.3, 24.4, 14.6, 19.5, 14.1, 14.3,\n",
       "        15.6, 10.5,  6.3, 19.3, 19.3, 13.4, 36.4, 17.8, 13.5, 16.5,  8.3,\n",
       "        14.3, 16. , 13.4, 28.6, 43.5, 20.2, 22. , 23. , 20.7, 12.5, 48.5,\n",
       "        14.6, 13.4, 23.7, 50. , 21.7, 39.8, 38.7, 22.2, 34.9, 22.5, 31.1,\n",
       "        28.7, 46. , 41.7, 21. , 26.6, 15. , 24.4, 13.3, 21.2, 11.7, 21.7,\n",
       "        19.4, 50. , 22.8, 19.7, 24.7, 36.2, 14.2, 18.9, 18.3, 20.6, 24.6,\n",
       "        18.2,  8.7, 44. , 10.4, 13.2, 21.2, 37. , 30.7, 22.9, 20. , 19.3,\n",
       "        31.7, 32. , 23.1, 18.8, 10.9, 50. , 19.6,  5. , 14.4, 19.8, 13.8,\n",
       "        19.6, 23.9, 24.5, 25. , 19.9, 17.2, 24.6, 13.5, 26.6, 21.4, 11.9,\n",
       "        22.6, 19.6,  8.5, 23.7, 23.1, 22.4, 20.5, 23.6, 18.4, 35.2, 23.1,\n",
       "        27.9, 20.6, 23.7, 28. , 13.6, 27.1, 23.6, 20.6, 18.2, 21.7, 17.1,\n",
       "         8.4, 25.3, 13.8, 22.2, 18.4, 20.7, 31.6, 30.5, 20.3,  8.8, 19.2,\n",
       "        19.4, 23.1, 23. , 14.8, 48.8, 22.6, 33.4, 21.1, 13.6, 32.2, 13.1,\n",
       "        23.4, 18.9, 23.9, 11.8, 23.3, 22.8, 19.6, 16.7, 13.4, 22.2, 20.4,\n",
       "        21.8, 26.4, 14.9, 24.1, 23.8, 12.3, 29.1, 21. , 19.5, 23.3, 23.8,\n",
       "        17.8, 11.5, 21.7, 19.9, 25. , 33.4, 28.5, 21.4, 24.3, 27.5, 33.1,\n",
       "        16.2, 23.3, 48.3, 22.9, 22.8, 13.1, 12.7, 22.6, 15. , 15.3, 10.5,\n",
       "        24. , 18.5, 21.7, 19.5, 33.2, 23.2,  5. , 19.1, 12.7, 22.3, 10.2,\n",
       "        13.9, 16.3, 17. , 20.1, 29.9, 17.2, 37.3, 45.4, 17.8, 23.2, 29. ,\n",
       "        22. , 18. , 17.4, 34.6, 20.1, 25. , 15.6, 24.8, 28.2, 21.2, 21.4,\n",
       "        23.8, 31. , 26.2, 17.4, 37.9, 17.5, 20. ,  8.3, 23.9,  8.4, 13.8,\n",
       "         7.2, 11.7, 17.1, 21.6, 50. , 16.1, 20.4, 20.6, 21.4, 20.6, 36.5,\n",
       "         8.5, 24.8, 10.8, 21.9, 17.3, 18.9, 36.2, 14.9, 18.2, 33.3, 21.8,\n",
       "        19.7, 31.6, 24.8, 19.4, 22.8,  7.5, 44.8, 16.8, 18.7, 50. , 50. ,\n",
       "        19.5, 20.1, 50. , 17.2, 20.8, 19.3, 41.3, 20.4, 20.5, 13.8, 16.5,\n",
       "        23.9, 20.6, 31.5, 23.3, 16.8, 14. , 33.8, 36.1, 12.8, 18.3, 18.7,\n",
       "        19.1, 29. , 30.1, 50. , 50. , 22. , 11.9, 37.6, 50. , 22.7, 20.8,\n",
       "        23.5, 27.9, 50. , 19.3, 23.9, 22.6, 15.2, 21.7, 19.2, 43.8, 20.3,\n",
       "        33.2, 19.9, 22.5, 32.7, 22. , 17.1, 19. , 15. , 16.1, 25.1, 23.7,\n",
       "        28.7, 37.2, 22.6, 16.4, 25. , 29.8, 22.1, 17.4, 18.1, 30.3, 17.5,\n",
       "        24.7, 12.6, 26.5, 28.7, 13.3, 10.4, 24.4, 23. , 20. , 17.8,  7. ,\n",
       "        11.8, 24.4, 13.8, 19.4, 25.2, 19.4, 19.4, 29.1,  7.2, 18.8, 19. ,\n",
       "        27. , 22.2, 24.5, 31.2, 22.9, 20.5, 23.2, 18.6, 14.5, 17.8, 50. ,\n",
       "        20.8, 24.3, 24.2, 19.8, 19.1, 22.7, 12. , 10.2, 20. , 18.5, 20.9,\n",
       "        23. , 27.5, 30.1,  9.5, 22. , 21.2, 14.1, 33.1, 23.4, 20.1,  7.4,\n",
       "        15.4, 23.8, 20.1, 24.5, 33. , 28.4, 14.1, 46.7, 32.5, 29.6, 28.4,\n",
       "        19.8, 20.2, 25. , 35.4, 20.3,  9.7, 14.5, 34.9, 26.6,  7.2, 50. ,\n",
       "        32.4, 21.6, 29.8, 13.1, 27.5, 21.2, 23.1, 21.9, 13. , 23.2,  8.1,\n",
       "         5.6, 21.7, 29.6, 19.6,  7. , 26.4, 18.9, 20.9, 28.1, 35.4, 10.2,\n",
       "        24.3, 43.1, 17.6, 15.4, 16.2, 27.1, 21.4, 21.5, 22.4, 25. , 16.6,\n",
       "        18.6, 22. , 42.8, 35.1, 21.5, 36. , 21.9, 24.1, 50. , 26.7, 25. ]))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tensorflow.keras.models.Sequential()\n",
    "model.add(tensorflow.keras.layers.BatchNormalization(input_shape=(13,)))\n",
    "model.add(tensorflow.keras.layers.Dense(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"sgd\", loss = \"mse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 354 samples, validate on 152 samples\n",
      "Epoch 1/100\n",
      "354/354 [==============================] - 1s 2ms/sample - loss: 236.8515 - val_loss: 2082.3011\n",
      "Epoch 2/100\n",
      "354/354 [==============================] - 0s 124us/sample - loss: 54.6071 - val_loss: 384.1278\n",
      "Epoch 3/100\n",
      "354/354 [==============================] - 0s 87us/sample - loss: 43.9958 - val_loss: 131.0491\n",
      "Epoch 4/100\n",
      "354/354 [==============================] - 0s 85us/sample - loss: 51.2062 - val_loss: 46.1247\n",
      "Epoch 5/100\n",
      "354/354 [==============================] - 0s 85us/sample - loss: 43.7117 - val_loss: 284.4395\n",
      "Epoch 6/100\n",
      "354/354 [==============================] - 0s 96us/sample - loss: 58.7224 - val_loss: 32.3588\n",
      "Epoch 7/100\n",
      "354/354 [==============================] - 0s 104us/sample - loss: 35.4978 - val_loss: 43.0525\n",
      "Epoch 8/100\n",
      "354/354 [==============================] - 0s 118us/sample - loss: 34.0017 - val_loss: 48.9767\n",
      "Epoch 9/100\n",
      "354/354 [==============================] - 0s 99us/sample - loss: 35.2649 - val_loss: 61.1536\n",
      "Epoch 10/100\n",
      "354/354 [==============================] - 0s 87us/sample - loss: 31.4815 - val_loss: 36.5619\n",
      "Epoch 11/100\n",
      "354/354 [==============================] - 0s 85us/sample - loss: 31.7829 - val_loss: 64.8794\n",
      "Epoch 12/100\n",
      "354/354 [==============================] - 0s 93us/sample - loss: 36.0726 - val_loss: 23.8486\n",
      "Epoch 13/100\n",
      "354/354 [==============================] - 0s 90us/sample - loss: 29.6958 - val_loss: 24.7563\n",
      "Epoch 14/100\n",
      "354/354 [==============================] - 0s 96us/sample - loss: 29.3658 - val_loss: 69.4939\n",
      "Epoch 15/100\n",
      "354/354 [==============================] - 0s 82us/sample - loss: 34.8694 - val_loss: 63.4726\n",
      "Epoch 16/100\n",
      "354/354 [==============================] - 0s 96us/sample - loss: 25.7180 - val_loss: 23.7651\n",
      "Epoch 17/100\n",
      "354/354 [==============================] - 0s 90us/sample - loss: 27.7646 - val_loss: 71.3713\n",
      "Epoch 18/100\n",
      "354/354 [==============================] - 0s 96us/sample - loss: 30.3753 - val_loss: 58.4387\n",
      "Epoch 19/100\n",
      "354/354 [==============================] - 0s 99us/sample - loss: 34.7164 - val_loss: 33.9011\n",
      "Epoch 20/100\n",
      "354/354 [==============================] - 0s 82us/sample - loss: 31.1913 - val_loss: 35.7636\n",
      "Epoch 21/100\n",
      "354/354 [==============================] - 0s 82us/sample - loss: 30.7764 - val_loss: 104.6133\n",
      "Epoch 22/100\n",
      "354/354 [==============================] - 0s 85us/sample - loss: 32.3021 - val_loss: 149.6422\n",
      "Epoch 23/100\n",
      "354/354 [==============================] - 0s 84us/sample - loss: 36.8195 - val_loss: 26.3926\n",
      "Epoch 24/100\n",
      "354/354 [==============================] - 0s 82us/sample - loss: 30.0906 - val_loss: 33.9036\n",
      "Epoch 25/100\n",
      "354/354 [==============================] - 0s 90us/sample - loss: 30.5394 - val_loss: 36.0728\n",
      "Epoch 26/100\n",
      "354/354 [==============================] - 0s 90us/sample - loss: 29.2129 - val_loss: 48.9951\n",
      "Epoch 27/100\n",
      "354/354 [==============================] - 0s 82us/sample - loss: 33.5619 - val_loss: 58.7704\n",
      "Epoch 28/100\n",
      "354/354 [==============================] - 0s 96us/sample - loss: 36.2280 - val_loss: 206.8194\n",
      "Epoch 29/100\n",
      "354/354 [==============================] - 0s 87us/sample - loss: 61.1057 - val_loss: 35.8277\n",
      "Epoch 30/100\n",
      "354/354 [==============================] - 0s 101us/sample - loss: 31.9176 - val_loss: 47.3181\n",
      "Epoch 31/100\n",
      "354/354 [==============================] - 0s 82us/sample - loss: 31.8382 - val_loss: 28.8680\n",
      "Epoch 32/100\n",
      "354/354 [==============================] - 0s 82us/sample - loss: 32.3299 - val_loss: 56.7275\n",
      "Epoch 33/100\n",
      "354/354 [==============================] - 0s 87us/sample - loss: 29.5141 - val_loss: 38.6150\n",
      "Epoch 34/100\n",
      "354/354 [==============================] - 0s 90us/sample - loss: 27.5050 - val_loss: 28.3615\n",
      "Epoch 35/100\n",
      "354/354 [==============================] - 0s 87us/sample - loss: 26.2313 - val_loss: 39.1101\n",
      "Epoch 36/100\n",
      "354/354 [==============================] - 0s 101us/sample - loss: 31.7535 - val_loss: 29.2472\n",
      "Epoch 37/100\n",
      "354/354 [==============================] - 0s 107us/sample - loss: 26.7992 - val_loss: 23.5384\n",
      "Epoch 38/100\n",
      "354/354 [==============================] - 0s 87us/sample - loss: 26.8039 - val_loss: 33.4060\n",
      "Epoch 39/100\n",
      "354/354 [==============================] - 0s 87us/sample - loss: 27.4314 - val_loss: 29.2087\n",
      "Epoch 40/100\n",
      "354/354 [==============================] - 0s 90us/sample - loss: 26.2385 - val_loss: 36.8924\n",
      "Epoch 41/100\n",
      "354/354 [==============================] - 0s 85us/sample - loss: 32.0237 - val_loss: 54.1457\n",
      "Epoch 42/100\n",
      "354/354 [==============================] - 0s 85us/sample - loss: 33.1521 - val_loss: 26.8317\n",
      "Epoch 43/100\n",
      "354/354 [==============================] - 0s 82us/sample - loss: 34.5148 - val_loss: 61.7510\n",
      "Epoch 44/100\n",
      "354/354 [==============================] - 0s 87us/sample - loss: 34.0565 - val_loss: 104.1310\n",
      "Epoch 45/100\n",
      "354/354 [==============================] - 0s 99us/sample - loss: 33.1376 - val_loss: 34.1880\n",
      "Epoch 46/100\n",
      "354/354 [==============================] - 0s 87us/sample - loss: 31.7968 - val_loss: 30.6142\n",
      "Epoch 47/100\n",
      "354/354 [==============================] - 0s 84us/sample - loss: 26.6432 - val_loss: 29.2569\n",
      "Epoch 48/100\n",
      "354/354 [==============================] - 0s 90us/sample - loss: 29.7041 - val_loss: 32.2377\n",
      "Epoch 49/100\n",
      "354/354 [==============================] - 0s 87us/sample - loss: 27.9195 - val_loss: 70.6274\n",
      "Epoch 50/100\n",
      "354/354 [==============================] - 0s 99us/sample - loss: 29.2189 - val_loss: 47.2748\n",
      "Epoch 51/100\n",
      "354/354 [==============================] - 0s 82us/sample - loss: 28.8012 - val_loss: 41.2599\n",
      "Epoch 52/100\n",
      "354/354 [==============================] - 0s 85us/sample - loss: 30.8691 - val_loss: 91.6101\n",
      "Epoch 53/100\n",
      "354/354 [==============================] - 0s 99us/sample - loss: 38.6710 - val_loss: 120.4383\n",
      "Epoch 54/100\n",
      "354/354 [==============================] - 0s 96us/sample - loss: 36.6457 - val_loss: 90.1530\n",
      "Epoch 55/100\n",
      "354/354 [==============================] - 0s 104us/sample - loss: 35.1455 - val_loss: 40.6205\n",
      "Epoch 56/100\n",
      "354/354 [==============================] - 0s 87us/sample - loss: 30.3844 - val_loss: 107.8418\n",
      "Epoch 57/100\n",
      "354/354 [==============================] - 0s 85us/sample - loss: 34.2708 - val_loss: 110.8595\n",
      "Epoch 58/100\n",
      "354/354 [==============================] - 0s 90us/sample - loss: 45.9138 - val_loss: 26.5280\n",
      "Epoch 59/100\n",
      "354/354 [==============================] - 0s 85us/sample - loss: 27.8036 - val_loss: 26.8650\n",
      "Epoch 60/100\n",
      "354/354 [==============================] - 0s 96us/sample - loss: 25.4552 - val_loss: 25.9310\n",
      "Epoch 61/100\n",
      "354/354 [==============================] - 0s 90us/sample - loss: 29.5612 - val_loss: 30.4997\n",
      "Epoch 62/100\n",
      "354/354 [==============================] - 0s 96us/sample - loss: 26.7372 - val_loss: 27.0298\n",
      "Epoch 63/100\n",
      "354/354 [==============================] - 0s 96us/sample - loss: 24.6686 - val_loss: 46.4698\n",
      "Epoch 64/100\n",
      "354/354 [==============================] - 0s 99us/sample - loss: 35.1058 - val_loss: 111.2691\n",
      "Epoch 65/100\n",
      "354/354 [==============================] - 0s 90us/sample - loss: 37.2957 - val_loss: 56.0587\n",
      "Epoch 66/100\n",
      "354/354 [==============================] - 0s 90us/sample - loss: 31.9126 - val_loss: 211.0239\n",
      "Epoch 67/100\n",
      "354/354 [==============================] - 0s 101us/sample - loss: 38.6667 - val_loss: 38.5370\n",
      "Epoch 68/100\n",
      "354/354 [==============================] - 0s 90us/sample - loss: 29.4620 - val_loss: 68.0858\n",
      "Epoch 69/100\n",
      "354/354 [==============================] - 0s 96us/sample - loss: 34.4736 - val_loss: 61.8562\n",
      "Epoch 70/100\n",
      "354/354 [==============================] - 0s 85us/sample - loss: 30.8955 - val_loss: 76.7146\n",
      "Epoch 71/100\n",
      "354/354 [==============================] - 0s 93us/sample - loss: 33.3298 - val_loss: 29.7100\n",
      "Epoch 72/100\n",
      "354/354 [==============================] - 0s 96us/sample - loss: 26.7109 - val_loss: 24.7014\n",
      "Epoch 73/100\n",
      "354/354 [==============================] - 0s 85us/sample - loss: 28.0100 - val_loss: 71.5149\n",
      "Epoch 74/100\n",
      "354/354 [==============================] - 0s 93us/sample - loss: 34.7317 - val_loss: 40.7077\n",
      "Epoch 75/100\n",
      "354/354 [==============================] - 0s 93us/sample - loss: 28.6556 - val_loss: 26.0764\n",
      "Epoch 76/100\n",
      "354/354 [==============================] - 0s 82us/sample - loss: 29.5286 - val_loss: 35.6068\n",
      "Epoch 77/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "354/354 [==============================] - 0s 96us/sample - loss: 32.7269 - val_loss: 140.1917\n",
      "Epoch 78/100\n",
      "354/354 [==============================] - 0s 82us/sample - loss: 43.5161 - val_loss: 42.2730\n",
      "Epoch 79/100\n",
      "354/354 [==============================] - 0s 85us/sample - loss: 26.7715 - val_loss: 48.4008\n",
      "Epoch 80/100\n",
      "354/354 [==============================] - 0s 87us/sample - loss: 30.7667 - val_loss: 37.8522\n",
      "Epoch 81/100\n",
      "354/354 [==============================] - 0s 85us/sample - loss: 29.0669 - val_loss: 37.3115\n",
      "Epoch 82/100\n",
      "354/354 [==============================] - 0s 93us/sample - loss: 27.7464 - val_loss: 35.3980\n",
      "Epoch 83/100\n",
      "354/354 [==============================] - 0s 90us/sample - loss: 35.1202 - val_loss: 25.4663\n",
      "Epoch 84/100\n",
      "354/354 [==============================] - 0s 87us/sample - loss: 28.9672 - val_loss: 31.1471\n",
      "Epoch 85/100\n",
      "354/354 [==============================] - 0s 85us/sample - loss: 28.4785 - val_loss: 28.0191\n",
      "Epoch 86/100\n",
      "354/354 [==============================] - 0s 87us/sample - loss: 30.1615 - val_loss: 102.2926\n",
      "Epoch 87/100\n",
      "354/354 [==============================] - 0s 90us/sample - loss: 40.9333 - val_loss: 124.0324\n",
      "Epoch 88/100\n",
      "354/354 [==============================] - 0s 79us/sample - loss: 36.5945 - val_loss: 27.6082\n",
      "Epoch 89/100\n",
      "354/354 [==============================] - 0s 90us/sample - loss: 31.9458 - val_loss: 48.5997\n",
      "Epoch 90/100\n",
      "354/354 [==============================] - 0s 93us/sample - loss: 34.0566 - val_loss: 30.7615\n",
      "Epoch 91/100\n",
      "354/354 [==============================] - 0s 85us/sample - loss: 32.7077 - val_loss: 258.8787\n",
      "Epoch 92/100\n",
      "354/354 [==============================] - 0s 87us/sample - loss: 64.0341 - val_loss: 34.5145\n",
      "Epoch 93/100\n",
      "354/354 [==============================] - 0s 87us/sample - loss: 29.9320 - val_loss: 87.3200\n",
      "Epoch 94/100\n",
      "354/354 [==============================] - 0s 85us/sample - loss: 30.7228 - val_loss: 25.5471\n",
      "Epoch 95/100\n",
      "354/354 [==============================] - 0s 82us/sample - loss: 27.8585 - val_loss: 35.7328\n",
      "Epoch 96/100\n",
      "354/354 [==============================] - 0s 87us/sample - loss: 36.1320 - val_loss: 61.0089\n",
      "Epoch 97/100\n",
      "354/354 [==============================] - 0s 87us/sample - loss: 35.0738 - val_loss: 34.7207\n",
      "Epoch 98/100\n",
      "354/354 [==============================] - 0s 90us/sample - loss: 27.9309 - val_loss: 36.6397\n",
      "Epoch 99/100\n",
      "354/354 [==============================] - 0s 87us/sample - loss: 28.4652 - val_loss: 31.5924\n",
      "Epoch 100/100\n",
      "354/354 [==============================] - 0s 90us/sample - loss: 26.3329 - val_loss: 41.8631\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1e9368108d0>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(features[0], features[1], epochs = 100, validation_split= 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_ = np.array([[0.04742,0,12.93,0,0.673,7.03,82.8,3.505,1,276,22,398.9,8.88]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.742e-02, 0.000e+00, 1.293e+01, 0.000e+00, 6.730e-01, 7.030e+00,\n",
       "        8.280e+01, 3.505e+00, 1.000e+00, 2.760e+02, 2.200e+01, 3.989e+02,\n",
       "        8.880e+00]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[19.691418]], dtype=float32)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(predict_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
