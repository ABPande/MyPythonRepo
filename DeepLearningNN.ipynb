{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear():\n",
    "    def __init__(self, in_, out_):\n",
    "        self.W = np.random.randn(in_,out_) * 0.01\n",
    "        self.b = np.zeros((1,out_))\n",
    "        self.params = [self.W, self.b]\n",
    "        self.gradW = None\n",
    "        self.gradb = None\n",
    "        self.gradInput = None\n",
    "    \n",
    "    def forward(self, X):\n",
    "        self.X = X\n",
    "        self.output = np.dot(X, self.W) + self.b\n",
    "        return self.output\n",
    "    \n",
    "    def backward(self, nextgrad):\n",
    "        self.gradW = np.dot(self.X.T, nextgrad)\n",
    "        self.gradb = np.sum(nextgrad, axis = 0)\n",
    "        self.gradInput = np.dot(nextgrad, self.W.T)\n",
    "        return self.gradInput, [self.gradW, self.gradb]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReLU():\n",
    "    def __init__(self):\n",
    "        self.params = []\n",
    "        self.gradInput = None\n",
    "    \n",
    "    def forward(self, X):\n",
    "        self.output = np.maximum(X,0)\n",
    "        return self.output\n",
    "    \n",
    "    def backward(self, nextgrad):\n",
    "        self.gradInput = nextgrad.copy()\n",
    "        self.gradInput [self.output<=0] = 0 \n",
    "        return self.gradInput, []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(X):\n",
    "    exp_x = np.exp(X - np.max(X, axis = 1, keepdims = True))\n",
    "    return exp_x/np.sum(exp_x, axis = 1, keepdims = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CrossEntropy():\n",
    "    def forward(self, X, y):\n",
    "        self.m = y.shape[0]\n",
    "        self.p = softmax(X)\n",
    "        cross_entropy = -np.log(self.p[range(self.m),y])\n",
    "        loss = np.sum(cross_entropy) /self.m\n",
    "        return loss\n",
    "    \n",
    "    def backward(self, X, y):\n",
    "        y_idx = y.argmax()\n",
    "        grad = softmax(X)\n",
    "        grad[range(self.m),y] -= 1\n",
    "        grad /=self.m\n",
    "        return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n",
      "(10000, 784)\n",
      "(60000,)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "from keras.utils import np_utils\n",
    "\n",
    "(train_features, train_targets), (test_features, test_targets) = mnist.load_data()\n",
    "\n",
    "train_features = train_features.reshape(60000,784)\n",
    "print (train_features.shape)\n",
    "test_features = test_features.reshape(10000,784)\n",
    "print (test_features.shape)\n",
    "\n",
    "train_features = train_features/255.0\n",
    "test_features = test_features/255.0\n",
    "\n",
    "print (train_targets.shape)\n",
    "print (test_targets.shape)\n",
    "\n",
    "X_train = train_features\n",
    "y_train = train_targets\n",
    "\n",
    "X_val = test_features\n",
    "y_val = test_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x72 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels are  [5 0 4 1 9 2 1 3 1 4]\n"
     ]
    }
   ],
   "source": [
    "plt.figure(figsize = (10,1) )\n",
    "for i in range(10):\n",
    "    plt.subplot(1,10,i+1)\n",
    "    plt.imshow(X_train[i].reshape(28,28), cmap = \"gray\")\n",
    "    plt.axis(\"off\")\n",
    "plt.show()\n",
    "print (\"labels are \", y_train[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN():\n",
    "    def __init__(self, lossfunc = CrossEntropy()):\n",
    "        self.params = []\n",
    "        self.layers = []\n",
    "        self.loss_func = lossfunc\n",
    "        self.grads = []\n",
    "    \n",
    "    def add_layer(self, layer):\n",
    "        self.layers.append(layer)\n",
    "        self.params.append(layer.params)\n",
    "    \n",
    "    def forward(self, X):\n",
    "        for layer in self.layers:\n",
    "            X = layer.forward(X)\n",
    "        return X\n",
    "    \n",
    "    def backward(self, nextgrad):\n",
    "        self.clear_grad_param()\n",
    "        for layer in reversed(self.layers):\n",
    "            nextgrad, grad = layer.backward(nextgrad)\n",
    "            self.grads.append(grad)\n",
    "        return self.grads\n",
    "    \n",
    "    def train_step(self, X, y):\n",
    "        out = self.forward(X)\n",
    "        loss = self.loss_func.forward(out, y)\n",
    "        nextgrad = self.loss_func.backward(out, y)\n",
    "        grads = self.backward(nextgrad)\n",
    "        return loss, grads\n",
    "    \n",
    "    def predict(self, X):\n",
    "        X = self.forward(X)\n",
    "        return np.argmax(X, axis = 1)\n",
    "\n",
    "    def predict_scores(self, X):\n",
    "        X = self.forward(X)\n",
    "        return X\n",
    "    \n",
    "    def clear_grad_param(self):\n",
    "        self.grads = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_params(velocity, params, grads, learning_rate = 0.01, mu = 0.9):\n",
    "    for v, p, g, in zip(velocity, params, reversed(grads)):\n",
    "        for i in range(len(g)):\n",
    "            v[i] = mu * v[i] + learning_rate * g[i]\n",
    "            p[i] -= v[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def minibatch (X, y, minibatch_size):\n",
    "    n = X.shape[0]\n",
    "    minibatches = []\n",
    "    permutation = np.random.permutation(X.shape[0])\n",
    "    X = X[permutation]\n",
    "    y = y[permutation]\n",
    "    \n",
    "    for i in range(0, n, minibatch_size):\n",
    "        X_batch = X[i:i + minibatch_size, :]\n",
    "        y_batch = y[i:i + minibatch_size, ]\n",
    "        minibatches.append((X_batch, y_batch))\n",
    "    \n",
    "    return minibatches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(net, X_train, y_train, minibatch_size, epoch, learning_rate, mu = 0.9, X_val=None, y_val = None):\n",
    "    val_loss_epoch = []\n",
    "    minibatches = minibatch(X_train, y_train, minibatch_size)\n",
    "    minibatches_val = minibatch(X_val, y_val, minibatch_size)\n",
    "        \n",
    "    for i in range (epoch):\n",
    "        loss_batch = []\n",
    "        val_loss_batch = []\n",
    "        velocity = []\n",
    "        for param_layer in net.params:\n",
    "            p = [np.zeros_like(param) for param in list(param_layer)]\n",
    "            velocity.append(p)\n",
    "            \n",
    "        for X_mini, y_mini in minibatches:\n",
    "            loss, grads = net.train_step(X_mini, y_mini)\n",
    "            loss_batch.append(loss)\n",
    "            update_params(velocity, net.params, grads, learning_rate = learning_rate, mu = mu)\n",
    "        \n",
    "        for X_mini_val, y_mini_val in minibatches_val:\n",
    "            val_loss, _ = net.train_step(X_mini, y_mini)\n",
    "            val_loss_batch.append(val_loss)\n",
    "        \n",
    "        m_train = X_train.shape[0]\n",
    "        m_val = X_val.shape[0]\n",
    "        \n",
    "        y_train_pred = np.array([], dtype = \"int64\")\n",
    "        y_val_pred = np.array([], dtype = \"int64\")\n",
    "        y_train1 = []\n",
    "        y_val1 = []        \n",
    "        for i in range(0, m_train, minibatch_size):\n",
    "            X_tr = X_train[i:i + minibatch_size, :]\n",
    "            y_tr = y_train[i:i + minibatch_size, ]\n",
    "            y_train1 = np.append(y_train1, y_tr)\n",
    "            y_train_pred = np.append(y_train_pred, net.predict(X_tr) )\n",
    "        \n",
    "        for i in range(0, m_val, minibatch_size):\n",
    "            X_va = X_val[i:i + minibatch_size, :]\n",
    "            y_va = y_val[i:i + minibatch_size, ]\n",
    "            y_val1 = np.append(y_val1, y_va)\n",
    "            y_val_pred = np.append(y_val_pred, net.predict(X_va) )\n",
    "            \n",
    "        train_acc = check_accuracy(y_train1, y_train_pred)\n",
    "        val_acc = check_accuracy(y_train1, y_train_pred)\n",
    "        \n",
    "        mean_train_loss = sum(loss_batch)/float(len(loss_batch))\n",
    "        mean_val_loss = sum(val_loss_batch)/float(len(val_loss_batch))\n",
    "        \n",
    "        val_loss_epoch.append(mean_val_loss)\n",
    "        print (mean_train_loss)\n",
    "        print (mean_val_loss)\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_accuracy(y_true, y_pred):\n",
    "    return (np.mean(y_true==y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4927763726985172\n",
      "0.2458195475383681\n",
      "0.18457461907675027\n",
      "0.18011661158148765\n",
      "0.13803881334084708\n",
      "0.14936240628967484\n",
      "0.11452662911961763\n",
      "0.13189732538172041\n",
      "0.1004949593539651\n",
      "0.11743195071970629\n",
      "0.0904879027008283\n",
      "0.10644472775527002\n",
      "0.08250660714563252\n",
      "0.10272161981652532\n",
      "0.07598187254962276\n",
      "0.09353892114219058\n",
      "0.07114469643902745\n",
      "0.09723847258224938\n",
      "0.06781262831815983\n",
      "0.10749690492632383\n"
     ]
    }
   ],
   "source": [
    "from random import shuffle\n",
    "\n",
    "input_dim = X_train.shape[1]\n",
    "\n",
    "iterations = 10\n",
    "learning_rate = 0.1\n",
    "hidden_nodes = 32\n",
    "output_nodes = 10\n",
    "\n",
    "nn = NN()\n",
    "nn.add_layer(Linear(input_dim, hidden_nodes))\n",
    "nn.add_layer(ReLU())\n",
    "nn.add_layer(Linear(hidden_nodes, output_nodes))\n",
    "\n",
    "nn =train(nn, X_train, y_train, minibatch_size=200, epoch = 10, learning_rate= learning_rate, X_val = X_val, y_val = y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1f8bc9b9278>"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_val[0].reshape(28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = nn.predict_scores(X_val[0])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ -3.43739463,  -3.31425712,   5.68262486,   6.95561397,\n",
       "        -9.00817415,   0.94006677, -16.39920135,  15.36538548,\n",
       "         1.38587014,   2.2015175 ])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7], dtype=int64)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.predict(X_val[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
