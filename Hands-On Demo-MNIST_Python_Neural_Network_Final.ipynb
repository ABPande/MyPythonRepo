{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AfIVI6MQiMzE"
   },
   "source": [
    "### MNIST neural network from scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xxZweULXiMzF"
   },
   "source": [
    "#### Fully Connected Layer (Linear Layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1FueIixfiMzG"
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "\n",
    "class Linear():\n",
    "    def __init__(self, in_size, out_size):\n",
    "        self.W = np.random.randn(in_size, out_size) * 0.01\n",
    "        self.b = np.zeros((1, out_size))\n",
    "        self.params = [self.W, self.b]\n",
    "        self.gradW = None\n",
    "        self.gradB = None\n",
    "        self.gradInput = None        \n",
    "\n",
    "    def forward(self, X):\n",
    "        self.X = X\n",
    "        self.output = np.dot(X, self.W) + self.b\n",
    "        return self.output\n",
    "\n",
    "    def backward(self, nextgrad):\n",
    "        self.gradW = np.dot(self.X.T, nextgrad)\n",
    "        self.gradB = np.sum(nextgrad, axis=0)\n",
    "        self.gradInput = np.dot(nextgrad, self.W.T)\n",
    "        return self.gradInput, [self.gradW, self.gradB]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "O33Noi4iiMzM"
   },
   "source": [
    "#### Rectified Linear Activation Layer (ReLU)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KOa9j3cfiMzN"
   },
   "outputs": [],
   "source": [
    "class ReLU():\n",
    "    def __init__(self):\n",
    "        self.params = []\n",
    "        self.gradInput = None\n",
    "\n",
    "    def forward(self, X):\n",
    "        self.output = np.maximum(X, 0)\n",
    "        return self.output\n",
    "\n",
    "    def backward(self, nextgrad):\n",
    "        self.gradInput = nextgrad.copy()\n",
    "        self.gradInput[self.output <=0] = 0\n",
    "        return self.gradInput, []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XUl0dk6HiMzR"
   },
   "source": [
    "#### Defining the softmax function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gUTsLik3iMzS"
   },
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    exp_x = np.exp(x - np.max(x, axis=1, keepdims=True))\n",
    "    return exp_x / np.sum(exp_x, axis=1, keepdims=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zocFN7QQiMzV"
   },
   "source": [
    "#### Defining the Cross Entropy Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_wYY1bnEiMzW"
   },
   "outputs": [],
   "source": [
    "class CrossEntropy:\n",
    "    def forward(self, X, y):\n",
    "        self.m = y.shape[0]\n",
    "        self.p = softmax(X)\n",
    "        cross_entropy = -np.log(self.p[range(self.m), y])\n",
    "        # loss = cross_entropy[0] / self.m         # please note this line was in the video however the correct line is the below one\n",
    "        loss = np.sum(cross_entropy) / self.m      # which involves taking a sum across the losses for all the examples in the batch\n",
    "        return loss\n",
    "    \n",
    "    def backward(self, X, y):\n",
    "        y_idx = y.argmax()        \n",
    "        grad = softmax(X)\n",
    "        grad[range(self.m), y] -= 1\n",
    "        grad /= self.m\n",
    "        return grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uFAwwd53iMza"
   },
   "source": [
    "#### Loading the MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "KJLO_akoiMzb",
    "outputId": "02d8bbc7-9dfe-4567-e5c6-2b490c2a0bf3"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n",
      "(10000, 784)\n",
      "(60000,)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "from keras.utils import np_utils\n",
    "\n",
    "(train_features, train_targets), (test_features, test_targets) = mnist.load_data()\n",
    "\n",
    "train_features = train_features.reshape(60000, 784)\n",
    "print(train_features.shape)\n",
    "test_features = test_features.reshape(10000, 784)\n",
    "print(test_features.shape)\n",
    "\n",
    "\n",
    "# # normalize inputs from 0-255 to 0-1\n",
    "train_features = train_features / 255.0\n",
    "test_features = test_features / 255.0\n",
    "\n",
    "print(train_targets.shape)\n",
    "print(test_targets.shape)\n",
    "\n",
    "X_train = train_features\n",
    "y_train = train_targets\n",
    "\n",
    "X_val = test_features\n",
    "y_val = test_targets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 116
    },
    "colab_type": "code",
    "id": "YS6LnJwviMzg",
    "outputId": "a10896db-c2ac-4137-8470-108ae06b5eaf"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x72 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label for each of the above image: [5 0 4 1 9 2 1 3 1 4]\n"
     ]
    }
   ],
   "source": [
    "# visualizing the first 10 images in the dataset and their labels\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(10, 1))\n",
    "for i in range(10):\n",
    "    plt.subplot(1, 10, i+1)\n",
    "    plt.imshow(X_train[i].reshape(28, 28), cmap=\"gray\")\n",
    "    plt.axis('off')\n",
    "plt.show()\n",
    "print('label for each of the above image: %s' % (y_train[0:10]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EJ587e81iMzk"
   },
   "source": [
    "#### Here, we define the container NN class that enables the forward prop and backward propagation of the entire network. Note, how this class enables us to add layers of different types and also correctly pass gradients using the chain rule."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "X3u-gxUJiMzk"
   },
   "outputs": [],
   "source": [
    "class NN():\n",
    "    def __init__(self, lossfunc=CrossEntropy()):\n",
    "        self.params = []\n",
    "        self.layers = []\n",
    "        self.loss_func = lossfunc\n",
    "        self.grads = []\n",
    "        \n",
    "    def add_layer(self, layer):\n",
    "        self.layers.append(layer)\n",
    "        self.params.append(layer.params)\n",
    "\n",
    "    def forward(self, X):\n",
    "        for layer in self.layers:\n",
    "            X = layer.forward(X)\n",
    "        return X\n",
    "    \n",
    "    def backward(self, nextgrad):\n",
    "        self.clear_grad_param()\n",
    "        for layer in reversed(self.layers):\n",
    "            nextgrad, grad = layer.backward(nextgrad)\n",
    "            self.grads.append(grad)\n",
    "        return self.grads\n",
    "    \n",
    "    def train_step(self, X, y):\n",
    "        out = self.forward(X)\n",
    "        loss = self.loss_func.forward(out,y)\n",
    "        nextgrad = self.loss_func.backward(out,y)\n",
    "        grads = self.backward(nextgrad)\n",
    "        return loss, grads\n",
    "    \n",
    "    def predict(self, X):\n",
    "        X = self.forward(X)\n",
    "        return np.argmax(X, axis=1)\n",
    "    \n",
    "    def predict_scores(self, X):\n",
    "        X = self.forward(X)\n",
    "        return X\n",
    "    \n",
    "    def clear_grad_param(self):\n",
    "        self.grads = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "M-NKsF22iMzn"
   },
   "source": [
    "#### Defining the update function (SGD with momentum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LsNd7D7BiMzo"
   },
   "outputs": [],
   "source": [
    "def update_params(velocity, params, grads, learning_rate=0.01, mu=0.9):\n",
    "    for v, p, g, in zip(velocity, params, reversed(grads)):\n",
    "        for i in range(len(g)):\n",
    "            v[i] = mu * v[i] + learning_rate * g[i]\n",
    "            p[i] -= v[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4qe-KMG_iMzs"
   },
   "source": [
    "#### Defining a function which gives us the minibatches (both the datapoint and the corresponding label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZFOyQ2ZGiMzs"
   },
   "outputs": [],
   "source": [
    "# get minibatches\n",
    "def minibatch(X, y, minibatch_size):\n",
    "    n = X.shape[0]\n",
    "    minibatches = []\n",
    "    permutation = np.random.permutation(X.shape[0])\n",
    "    X = X[permutation]\n",
    "    y = y[permutation]\n",
    "    \n",
    "    for i in range(0, n , minibatch_size):\n",
    "        X_batch = X[i:i + minibatch_size, :]\n",
    "        y_batch = y[i:i + minibatch_size, ]\n",
    "        minibatches.append((X_batch, y_batch))\n",
    "        \n",
    "    return minibatches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bdX0EnUgiMzw"
   },
   "source": [
    "#### The traning loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DM7XtCTjiMzx"
   },
   "outputs": [],
   "source": [
    "def train(net, X_train, y_train, minibatch_size, epoch, learning_rate, mu=0.9, X_val=None, y_val=None):\n",
    "    val_loss_epoch = []\n",
    "    minibatches = minibatch(X_train, y_train, minibatch_size)\n",
    "    minibatches_val = minibatch(X_val, y_val, minibatch_size)\n",
    "\n",
    "    for i in range(epoch):\n",
    "        loss_batch = []\n",
    "        val_loss_batch = []\n",
    "        velocity = []\n",
    "        for param_layer in net.params:\n",
    "            p = [np.zeros_like(param) for param in list(param_layer)]\n",
    "            velocity.append(p)\n",
    "            \n",
    "        for X_mini, y_mini in minibatches:\n",
    "            loss, grads = net.train_step(X_mini, y_mini)\n",
    "            loss_batch.append(loss)\n",
    "            update_params(velocity, net.params, grads, learning_rate=learning_rate, mu=mu)\n",
    "\n",
    "        for X_mini_val, y_mini_val in minibatches_val:\n",
    "            val_loss, _ = net.train_step(X_mini, y_mini)\n",
    "            val_loss_batch.append(val_loss)\n",
    "\n",
    "        m_train = X_train.shape[0]\n",
    "        m_val = X_val.shape[0]\n",
    "        \n",
    "        y_train_pred = np.array([], dtype=\"int64\")\n",
    "        y_val_pred = np.array([], dtype=\"int64\")\n",
    "        y_train1 = []\n",
    "        y_val1 = []\n",
    "        for i in range(0, m_train, minibatch_size):\n",
    "            X_tr = X_train[i:i + minibatch_size, : ]\n",
    "            y_tr = y_train[i:i + minibatch_size,]\n",
    "            y_train1 = np.append(y_train1, y_tr)\n",
    "            y_train_pred = np.append(y_train_pred, net.predict(X_tr))\n",
    "\n",
    "        for i in range(0, m_val, minibatch_size):\n",
    "            X_va = X_val[i:i + minibatch_size, : ]\n",
    "            y_va = y_val[i:i + minibatch_size,]\n",
    "            y_val1 = np.append(y_val1, y_va)\n",
    "            y_val_pred = np.append(y_val_pred, net.predict(X_va))\n",
    "            \n",
    "        train_acc = check_accuracy(y_train1, y_train_pred)\n",
    "        val_acc = check_accuracy(y_val1, y_val_pred)\n",
    "\n",
    "        mean_train_loss = sum(loss_batch) / float(len(loss_batch))\n",
    "        mean_val_loss = sum(val_loss_batch) / float(len(val_loss_batch))\n",
    "        \n",
    "        val_loss_epoch.append(mean_val_loss)\n",
    "        print(\"Loss = {0} | Training Accuracy = {1} | Val Loss = {2} | Val Accuracy = {3}\".format(mean_train_loss, train_acc, mean_val_loss, val_acc))\n",
    "    return net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JauSFCZZiMz2"
   },
   "source": [
    "#### Checking the accuracy of the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UlnmjqaviMz3"
   },
   "outputs": [],
   "source": [
    "def check_accuracy(y_true, y_pred):\n",
    "    return np.mean(y_pred == y_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "I_JSqjs9iMz7"
   },
   "source": [
    "#### Invoking all that we have created until now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "colab_type": "code",
    "id": "ipPGnUmgiMz8",
    "outputId": "a593b333-1015-4f04-8de8-66bcb08cbf70"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss = 0.4791551353424333 | Training Accuracy = 0.9438833333333333 | Val Loss = 0.2118632484800749 | Val Accuracy = 0.9446\n",
      "Loss = 0.18338284646631461 | Training Accuracy = 0.9601333333333333 | Val Loss = 0.15541245106471274 | Val Accuracy = 0.9546\n",
      "Loss = 0.1391860577604038 | Training Accuracy = 0.9668333333333333 | Val Loss = 0.12830266722743913 | Val Accuracy = 0.9581\n",
      "Loss = 0.11764397114848864 | Training Accuracy = 0.9696833333333333 | Val Loss = 0.1283833638201093 | Val Accuracy = 0.9616\n",
      "Loss = 0.10326780002975569 | Training Accuracy = 0.97335 | Val Loss = 0.13526578540239517 | Val Accuracy = 0.9627\n",
      "Loss = 0.0941153560658772 | Training Accuracy = 0.9753166666666667 | Val Loss = 0.13173557654410664 | Val Accuracy = 0.966\n",
      "Loss = 0.08662006467276366 | Training Accuracy = 0.9776666666666667 | Val Loss = 0.12723720481911646 | Val Accuracy = 0.9681\n",
      "Loss = 0.07928892428236908 | Training Accuracy = 0.9782166666666666 | Val Loss = 0.13186998743976708 | Val Accuracy = 0.9671\n",
      "Loss = 0.07434691727694787 | Training Accuracy = 0.9794833333333334 | Val Loss = 0.1229401228670613 | Val Accuracy = 0.9671\n",
      "Loss = 0.0694617182839389 | Training Accuracy = 0.9794 | Val Loss = 0.12343299450485913 | Val Accuracy = 0.9659\n"
     ]
    }
   ],
   "source": [
    "from random import shuffle\n",
    "\n",
    "## input size\n",
    "input_dim = X_train.shape[1]\n",
    "\n",
    "## hyperparameters\n",
    "iterations = 10\n",
    "learning_rate = 0.1\n",
    "hidden_nodes = 32\n",
    "output_nodes = 10\n",
    "\n",
    "## define neural net\n",
    "nn = NN()\n",
    "nn.add_layer(Linear(input_dim, hidden_nodes))\n",
    "nn.add_layer(ReLU())\n",
    "nn.add_layer(Linear(hidden_nodes, output_nodes))\n",
    "\n",
    "nn = train(nn, X_train , y_train, minibatch_size=200, epoch=10, \\\n",
    "           learning_rate=learning_rate, X_val=X_val, y_val=y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2pnlNifKiM0B"
   },
   "source": [
    "#### fprop a single image and showing its prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 286
    },
    "colab_type": "code",
    "id": "A1Df46k3iM0C",
    "outputId": "a60b8210-a7f8-4a09-80ea-5568610a497b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x213bcdf1588>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_val[0].reshape(28,28), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7lyqu36iiM0G"
   },
   "outputs": [],
   "source": [
    "# Predict Scores for each class\n",
    "prediction = nn.predict_scores(X_val[0])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "LDTSzeTkiM0J",
    "outputId": "cc7ec49a-509b-4de9-9d91-c7b8039d9a47",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores\n",
      "[  1.23606307  -3.47262699   4.07818463   7.72462618 -18.71025684\n",
      "  -1.52207929 -16.07446071  17.5757969    3.4592239    6.37985234]\n"
     ]
    }
   ],
   "source": [
    "print (\"Scores\")\n",
    "print (prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "HTIiNdJliM0M",
    "outputId": "c1ad281c-1d1e-4b75-977f-53a48b7fa69c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "I9NyUYaViM0P",
    "outputId": "5a3c037f-ca78-46b1-8cd2-ef6fc5da38d8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_class = nn.predict(X_val[0])[0]\n",
    "predict_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "u6_bSLc2iM0R",
    "outputId": "a02ae4d2-114b-4837-da14-e9152a612726"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Original class\n",
    "y_val[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "MNIST_Python_Neural_Network_Final.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
